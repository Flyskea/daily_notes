
# 1. CAdvisor 部署

## Docker 部署

``` shell
VERSION=v0.36.0 # use the latest release version from https://github.com/google/cadvisor/releases
sudo docker run \
  --volume=/:/rootfs:ro \
  --volume=/var/run:/var/run:ro \
  --volume=/sys:/sys:ro \
  --volume=/var/lib/docker/:/var/lib/docker:ro \
  --volume=/dev/disk/:/dev/disk:ro \
  --publish=8080:8080 \
  --detach=true \
  --name=cadvisor \
  --privileged \
  --device=/dev/kmsg \
  gcr.io/cadvisor/cadvisor:$VERSION
```

# 2. CAdvisor 原理分析

以下是 main 函数代码，会对代码进行简单注解，并对代码进行一定程度上的精简，其代码路径为：/cadvisor/cmd/cadvisor. Go

根据以下代码可以总结 cAdvisor 主要完成了以下几个工作：

- 提供 API 给外部使用，包括一般 API 接口和 prometheus 接口
- 可实现第三方数据存储，支持 bigquery、es、influxdb、kafka、redis、statsd、stdout
- 收集数据包括 container、process、machine、Go runtime

```go
func main() {
    klog.InitFlags(nil)
    defer klog.Flush()
    flag.Parse()

    if *versionFlag {
        fmt.Printf("cAdvisor version %s (%s)\n", version.Info["version"], version.Info["revision"])
        os.Exit(0)
    }
    // 拿到所有需要收集的metrics类型，即从全量的metrics类型中，排除掉flag.disable_metrics，剩余的metrics集
    // 返回的值大概为container.MetricSet{
    //                     CpuUsageMetrics:                struct{}{}, //cpu
    //                    ProcessSchedulerMetrics:        struct{}{}, //sched
    //                    PerCpuUsageMetrics:             struct{}{}, //precpu
    //                    ....}
    includedMetrics := toIncludedMetrics(ignoreMetrics.MetricSet)

    // 利用cpu个数或是flag.max_procs，设置最大可执行的cpu个数
    setMaxProcs()

    //1. 初始化本地内存
    //2. 初始化存储介质，可初始化多个，支持：bigquery，es,influxdb,kafka,redis,statsd,stdout【用flag.storage_driver】
    //3. 定时将数据存入存储介质中【flag.storage_duration】 ？？
    memoryStorage, err := NewMemoryStorage()
    if err != nil {
        klog.Fatalf("Failed to initialize storage driver: %s", err)
    }

    // 系统fs对象
    sysFs := sysfs.NewRealSysFs()

    // 利用证书，创建http 的 client
    collectorHttpClient := createCollectorHttpClient(*collectorCert, *collectorKey)

    // 创建resourceManager
    resourceManager, err := manager.New(memoryStorage, sysFs, housekeepingConfig, includedMetrics, &collectorHttpClient, strings.Split(*rawCgroupPrefixWhiteList, ","), *perfEvents)
    if err != nil {
        klog.Fatalf("Failed to create a manager: %s", err)
    }

    mux := http.NewServeMux()

    if *enableProfiling {
        mux.HandleFunc("/debug/pprof/", pprof.Index)
        mux.HandleFunc("/debug/pprof/cmdline", pprof.Cmdline)
        mux.HandleFunc("/debug/pprof/profile", pprof.Profile)
        mux.HandleFunc("/debug/pprof/symbol", pprof.Symbol)
    }

    // Register all HTTP handlers.
    err = cadvisorhttp.RegisterHandlers(mux, resourceManager, *httpAuthFile, *httpAuthRealm, *httpDigestFile, *httpDigestRealm, *urlBasePrefix)
    if err != nil {
        klog.Fatalf("Failed to register HTTP handlers: %v", err)
    }

    containerLabelFunc := metrics.DefaultContainerLabels
    if !*storeContainerLabels {
        whitelistedLabels := strings.Split(*whitelistedContainerLabels, ",")
        containerLabelFunc = metrics.BaseContainerLabels(whitelistedLabels)
    }

    // Register Prometheus collector to gather information about containers, Go runtime, processes, and machine
    cadvisorhttp.RegisterPrometheusHandler(mux, resourceManager, *prometheusEndpoint, containerLabelFunc, includedMetrics)

    // Start the manager.
    if err := resourceManager.Start(); err != nil {
        klog.Fatalf("Failed to start manager: %v", err)
    }

    // Install signal handler. 
    installSignalHandler(resourceManager)

    klog.V(1).Infof("Starting cAdvisor version: %s-%s on port %d", version.Info["version"], version.Info["revision"], *argPort)

    rootMux := http.NewServeMux()
    rootMux.Handle(*urlBasePrefix+"/", http.StripPrefix(*urlBasePrefix, mux))

    addr := fmt.Sprintf("%s:%d", *argIp, *argPort)
    klog.Fatal(http.ListenAndServe(addr, rootMux))
}
```

其中 resourceManager 类型是 manager，粗略浏览下 manager 结构的字段以及相关功能

```go
type manager struct {
    // 当前受到监控的容器存在一个map中 containerData结构中包括了对容器的各种具体操作方式和相关信息
    containers               map[namespacedContainerName]*containerData
    // 对map中数据存取时采用的Lock
    containersLock           sync.RWMutex
    // 缓存在内存中的数据 主要是容器的相关信息
    memoryCache              *memory.InMemoryCache
    // host上的实际文件系统的相关信息
    fsInfo                   fs.FsInfo
    // 系统fs对象，里面有一些查询系统文件的方法
    sysFs                    sysfs.SysFs
    machineMu                sync.RWMutex // protects machineInfo
    // machine的相关信息 cpu memory network system信息等等
    machineInfo              info.MachineInfo
    // 用于存放退出信号的channel manager关闭的时候会给其中的channel发送退出信号
    quitChannels             []chan error
    //cadvisor本身所运行的那个容器(如果cadvisor运行在容器中)
    cadvisorContainer        string
    // 是否在hostnamespace中？
    inHostNamespace          bool
    // 对event相关操作进行的封装
    eventHandler             events.EventManager
    // manager的启动时间
    startupTime              time.Time
    // 在内存中保留数据的时间 也就是下次开始搜集容器相关信息并且更新内存信息的时间
    maxHousekeepingInterval  time.Duration
    // 是否允许动态设置dynamic housekeeping
    allowDynamicHousekeeping bool
    includedMetrics          container.MetricSet
    containerWatchers        []watcher.ContainerWatcher
    eventsChannel            chan watcher.ContainerEvent
    collectorHTTPClient      *http.Client
    nvidiaManager            stats.Manager
    perfManager              stats.Manager
    resctrlManager           stats.Manager
    // List of raw container cgroup path prefix whitelist.
    rawContainerCgroupPathPrefixWhiteList []string
}
```

## CAdvisor 数据采集分析

CAdvisor的数据采集分为两个部分 machineInfo 和 containerInfo。以下就详细介绍这两部分数据采集的过程。对数据采集需要用到 resourceManager，这是对数据采集的抽象，其结构体内容的具体介绍见。其数据采集开始代码是 `/cmd/cadvisor.go -> main.go` 中的代码：

```go
resourceManager, err := manager.New(memoryStorage, sysFs, housekeepingConfig, includedMetrics, &collectorHttpClient, strings.Split(*rawCgroupPrefixWhiteList, ","), *perfEvents)
if err != nil {
    klog.Fatalf("Failed to create a manager: %s", err)
}

// Start the manager.
if err := resourceManager.Start(); err != nil {
    klog.Fatalf("Failed to start manager: %v", err)
}
```

### 数据采集结构图

![img](picture/13639aefebea9f474ef560d87544090a_MD5.png)

### MachineInfo

machineInfo 的数据采集具体代码，主要是 `/machine/info.go -> Info()` ，在 `new manager` 的时候会去调用一次这个方法，主要是读取系统文件（具体文件见上面的“整体结构图”），将数据放入到m.MachineInfo 中，后续在 Start 方法中，起一个协程，定时调用该方法，更新本地 cache。相关代码地址如下：

```go
/machine/info.go
/machine/machine.go
/machine/operatingsystem_unix.go
/machine/operatingsystem_windows.go
```

### ContainerInfo

整体的 containerInfo 的数据采集，由 /manager/manager. Go -> Start () 开始，起整体流程图如下：

![img](picture/d10f7f155a73e08020ea4aebd4982dfa_MD5.png)

整体的流程的可以概括为两各部分：

1. 利用 inotify 去 watch cgroupPath，监控该目录下的变更，拿到该目录下的增删改查事件，也就知道 container 的变更，从而动态更新 cache 中的数据
2. 定时 check，cache 中的m.containers 和主动去拿获取目前存在的 container，对整体做一个 diff，从而更新 cache 中的数据

#### 创建 Container

其代码路径为 /manager/manager. Go -> CreateContainer , 具体代码如下，详细解析可以看代码中的注释（代码有做一些删减）。

```go
// Create a container.
func (m *manager) createContainer(containerName string, watchSource watcher.ContainerWatchSource) error {
    m.containersLock.Lock()
    defer m.containersLock.Unlock()

    return m.createContainerLocked(containerName, watchSource)
}

func (m *manager) createContainerLocked(containerName string, watchSource watcher.ContainerWatchSource) error {
    namespacedName := namespacedContainerName{
        Name: containerName,
    }

    // 查看该container是否以及存在，如果已存在，则直接return
    if _, ok := m.containers[namespacedName]; ok {
        return nil
    }

    // for (factories) 判断是否能创建handler，如果可以则创建handler。
    // 该handler实现了 ContainerHandler的interface，里面有GetSpec()、GetStats()、ListContainers等方法
    handler, accept, err := container.NewContainerHandler(containerName, watchSource, m.inHostNamespace)
    if err != nil {
        return err
    }
    if !accept {
        // ignoring this container.
        klog.V(4).Infof("ignoring container %q", containerName)
        return nil
    }

    logUsage := *logCadvisorUsage && containerName == m.cadvisorContainer
    // 创建 containerData struct{}结构体的对象
    cont, err := newContainerData(containerName, m.memoryCache, handler, logUsage, collectorManager, m.maxHousekeepingInterval, m.allowDynamicHousekeeping, clock.RealClock{})
    if err != nil {
        return err
    }
    ......

    // 将该container及其所有的aliases，放入到m.containers中
    m.containers[namespacedName] = cont
    for _, alias := range cont.info.Aliases {
        m.containers[namespacedContainerName{
            Namespace: cont.info.Namespace,
            Name:      alias,
        }] = cont
    }

    klog.V(3).Infof("Added container: %q (aliases: %v, namespace: %q)", containerName, cont.info.Aliases, cont.info.Namespace)
    ......
    
    // 构建 event，找到到合适的m.eventHandler. Watchers 的*[]watchers，放入到*[]watchers 的 EventChannel. Channel 中
    NewEvent := &info. Event{
        ContainerName: contRef. Name,
        Timestamp:     contSpec. CreationTime,
        EventType:     info. EventContainerCreation,
    }
    err = m.eventHandler.AddEvent (newEvent)
    If err != nil {
        Return err
    }

    // Start the container's housekeeping.
    // 开启一个 housekeeping 的协程，定时调用 updateStats ()，即更新 cont 的数据
    Return cont.Start ()
}
```

其中 m.eventHandler.AddEvent (newEvent) ，其逻辑是找到到合适的 m.eventHandler. Watchers 的[]watchers，再将 newEvent 分别放入到[]watchers 中，其中根据条件匹配到合适的[]watchers 逻辑如下：

- Watcher. Request. SndTime< newEvent. Timestamp< watcher. Request. EndTime
- NewEvent. EventType 在 watcher. Request. EventType 中有
- NewEvent. ContainerName 的前缀是 watcher. Request. ContainerName

#### 检测子容器

其代码路径为 /manager/manager. Go -> detectSubcontainers () , 主要是拿到 containerName=“/”下的所有 container 和 m.containers 做 diff，获取新增的容器 added 和已删除的容器 removed

- Added：对于 added 的容器调用m.CreateContainer ()（具体可参考：4.1 创建 container）
- Removed：对于 removed 的容器调用m.destroyContainer ()，将该容器及其 aliases 在 cache 中的记录全部删除掉

其 diff 具体逻辑如下图：

![img](picture/2fa9f8c67d6f9aab62ea22af7298e582_MD5.png)

#### Watch

其代码路径为 /manager/manager. Go -> watchForNewContainers (quit chan error)  
用的是 k 8 s. Io/utils/inotify 中的 watch 功能，即 watch 一个目录，从而拿到该目录下的所有变更。所以这里利用的是 inotify 来 watch cgroupPath，从而 watch 到 container 的变更

- 调用m.containerWatchers 中 watch 的 start ()，watch cgroupPaths 中的变化，获取该目录变更 event，并将得到的 event，放入条件匹配的 watch 的 EventChannel.Channel 中
    
- 调用 detectSubContainers (“/”) （具体可参考：4.2 检测子容器）
    
- go func{}处理以上的到的 event，对于 add 事件调用 m.CreateContainer () ，对于 delete 事件调用 m.destroyContainer () ，收到 quit 信号，则退出协程
    

#### 全局更新

其代码路径为 /manager/manager. Go -> globalHousekeeping (quit chan error) ，主要是定时调用m.detectSubcontainers ("/")，具体逻辑可参考`检测子容器`。间隔时间：globalHousekeepingInterval

```go
Func (m *manager) globalHousekeeping (quit chan error) {
    // longHousekeeping := min (100 ms，*globalHousekeepingInterval / 2)
    LongHousekeeping := 100 * time. Millisecond
    If *globalHousekeepingInterval/2 < longHousekeeping {
        LongHousekeeping = *globalHousekeepingInterval / 2
    }

    // 定时，间隔时间 *globalHousekeepingInterval
    Ticker := time.NewTicker (*globalHousekeepingInterval)
    For {
        Select {
        Case t := <-ticker. C:
            Start := time.Now ()

            // Check for new containers.
            err := m.detectSubcontainers ("/")
            If err != nil {
                Klog.Errorf ("Failed to detect containers: %s", err)
            }

            // housekeeping 耗时超过 longHousekeeping，则打印一条日志
            Duration := time.Since (start)
            If duration >= longHousekeeping {
                klog.V (3). Infof ("Global Housekeeping (%d) took %s", t.Unix (), duration)
            }
        Case <-quit:
            // Quit if asked to do so.
            Quit <- nil
            Klog.Infof ("Exiting global housekeeping thread")
            Return
        }
    }
}
```

## CAdvisor 数据存储分析

CAdvisor 不仅会在本地存储，用于 prometheus 拉取，而且还支持将数据存入第三方存储介质，用于数据的持久化，其逻辑相对简单，但是却很重要。

### 存储核心代码

```go
Cadvisor/cmd/storagedriver. Go

// 主要用于返回，各第三方 init 时放入 map 中的 client，以及和 storage 相关的 flag
Storage/* 

// 主要是一些创建 storage 的 client，AddStats，Close 方法
Cadvisor/cmd/storage/bigquery/*
Cadvisor/cmd/storage/elasticsearch/*
Cadvisor/cmd/storage/influxdb/*
Cadvisor/cmd/storage/kafka/*
Cadvisor/cmd/storage/redis/*
Cadvisor/cmd/storage/statsd/*
Cadvisor/cmd/storage/stdout/*

// 本地 cache 相关操作
Utils/timed_store. Go
```

### 代码入口

在真正执行 add 之前，需要初始化存储对象。数据存储最重要的结构体是 InMamoryCache，其具体结构如下，具体逻辑看注释：

```go
Type InMemoryCache struct {
    // 读写锁
    Lock              sync. RWMutex
    // container 本地 cache
    ContainerCacheMap map[string]*containerCache
    // 最大存活时间，这个在下面的存储过程中会用到
    MaxAge            time. Duration
    // 不同第三方存储实现的 interface
    Backend           []storage. StorageDriver
}
```

初始调用在 main 函数中的

```go
Func main () {    
    ....
    
    MemoryStorage, err := NewMemoryStorage ()
    If err != nil {
        Klog.Fatalf ("Failed to initialize storage driver: %s", err)
    }
    
    ....
}
```

其中 NewMemoryStorage () 函数在 cmd/storagedriver. Go 中，具体代码如下：

```go
// NewMemoryStorage creates a memory storage with an optional backend storage option.
Func NewMemoryStorage () (*memory. InMemoryCache, error) {
    BackendStorages := []storage. StorageDriver{}
    // storageDriver: flag. Storage_driver 启动时输入，多个存储介质用逗号分割（默认为空）
    For _, driver := range strings.Split (*storageDriver, ",") {
        If driver == "" {
            Continue
        }
        // 返回的是各第三方存储的 StorageDriver，以 elasticsearch 为例，就是
        // /cmd/internal/storage/elasticsearch/elasticsearch. Go -> func new () (storage. StorageDriver, error)
        Storage, err := storage.New (driver)
        If err != nil {
            Return nil, err
        }
        BackendStorages = append (backendStorages, storage)
        Klog.V (1). Infof ("Using backend storage type %q", driver)
    }
    Klog.V (1). Infof ("Caching stats in memory for %v", *storageDuration)
    
    // *InMemoryCache，其中 maxAge 就是 flag. Storage_duration 启动输入的值（默认2m）
    Return memory.New (*storageDuration, backendStorages), nil
}
```

### 数据存储过程

真正数据的存储过程分为两个部分：本地存储和第三方介质存储

- 本地存储：
	-  InMemoryCache. ContainerCacheMap 是一个 map，其具体结构为 map\[string\]*ContainerCache，其 key 是 container 的 name，value 是 ContainerCache，先判断该 map 中是否有 containerName 的数据，如果没有则新增
	- 对 containerName 相对应的 ContainerCache 插入数据，插入数据的步骤分三步：
		- 将数据根据 timestamp 插入到相应位置
		- 将 TimeStore. Buffer 中 timestamp < 刚插入数据的 timestamp - age 的数据 remove 掉
		- 查看 buffer 中数据个数 > maxItems，将 timestamp 小的数据 remove 掉
- 第三方介质存储：for bankend 中的方法，调用各介质的 AddStats 方法，将数据存入

具体调用过程可参考以下图：

![img](picture/cb1314650a925f1d42535f895febd3f0_MD5.png)