在网络系统中，使用速率限制器来控制客户端或服务发送的流量速率。在 HTTP 世界中，速率限制器限制在指定时间段内允许发送的客户端请求数量。如果 API 请求计数超过速率限制器定义的阈值，所有超过的调用都将被阻止。以下是一些例子：
- 用户每秒最多只能发布 2 篇帖子。
- 同一 IP 地址每天最多创建 10 个账号。
- 同一设备每周最多可以领取 5 次奖励。
在本章中，你被要求设计一个速率限制器。在开始设计之前，我们首先看一下使用 API 速率限制器的好处：
- 防止由拒绝服务（DoS）攻击引起的资源耗尽 [\[1\]]( https://cloud.google.com/solutions/rate-limitingstrategies-techniques )。几乎所有大型科技公司发布的 API 都实施了某种形式的速率限制。例如，Twitter 将每 3 小时内的推文数量限制为 300 条[\[2\]]( https://developer.twitter.com/en/docs/basics/rate-limits )。Google 文档 API 的默认限制如下：每个用户每 60 秒的读取请求限制为 300 次 [\ [3\]]( https://developers.google.com/docs/api/limits )。速率限制器通过阻止超额调用来防止意外或故意的 DoS 攻击。
- 降低成本。限制超额请求意味着减少服务器数量，并将更多资源分配给高优先级的 API。对于使用付费第三方 API 的公司来说，速率限制非常重要。例如，对于以下外部 API 的调用，你按每次调用收费：信用检查、支付、检索健康记录等。限制调用次数对于降低成本至关重要。
- 防止服务器过载。为了降低服务器负载，使用速率限制器来过滤掉由机器人或用户不当行为引起的过多请求。

## 第一步 - 理解问题并确定设计范围

速率限制可以使用不同的算法来实现，每种算法都有其优缺点。面试官和候选人之间的互动有助于澄清我们要构建的速率限制器的类型。

候选人：我们要设计什么类型的速率限制器？是客户端的速率限制器还是服务器端的 API 速率限制器？ 
面试官：很好的问题。我们重点关注服务器端的API速率限制器。

候选人：速率限制器是基于 IP、用户 ID 还是其他属性来限制 API 请求的频率？
面试官：速率限制器应具备足够的灵活性，以支持不同的限制规则集。

候选人：系统的规模如何？是为初创公司还是为拥有大量用户的大公司构建的？
面试官：系统必须能够处理大量的请求。

候选人：系统是否在分布式环境中工作？
面试官：是的。

候选人：速率限制器是一个单独的服务，还是应该在应用代码中实现？
面试官：这是一个由你决定的设计选择。

候选人：我们需要通知被限制的用户吗？
面试官：是的。

需求以下是该系统的需求摘要： 
- 准确限制过多的请求。 
- 低延迟。速率限制器不应该拖慢 HTTP 响应时间。 
- 尽可能少地使用内存。 
- 分布式速率限制。速率限制器可以在多个服务器或进程之间共享。
- 异常处理。当用户的请求被限制时，向其显示明确的异常信息。 
- 高容错性。如果速率限制器出现任何问题（例如，缓存服务器离线），不应影响整个系统。

## 第二步 - 提出高级设计并获得认可

让我们保持简单，使用基本的客户端和服务器模型进行通信。

### 在哪里放置速率限制器 ？

直观上，你可以在客户端或服务器端实现速率限制器。

- 客户端实现。一般来说，客户端是一个不可靠的位置来实施速率限制，因为恶意用户可以轻易伪造客户端请求。此外，我们可能无法控制客户端实现。
- 服务器端实现。图 4-1 显示了一个放置在服务器端的速率限制器。

![Where to put the rate limiter](Pasted%20image%2020230529132752.png)

除了客户端和服务器端的实现方式，还有一种替代方式。我们可以在 API 服务器之外创建一个速率限制器中间件，如图 4-2 所示，来限制对 API 的请求。

![middleware](Pasted%20image%2020230529133138.png)

让我们使用图 4-3 中的示例来说明在此设计中速率限制的工作原理。假设我们的 API 每秒允许 2 个请求，而客户端在一秒内发送了 3 个请求到服务器。前两个请求被路由到 API 服务器，但速率限制器中间件限制了第三个请求，并返回 HTTP 状态码 429。HTTP 429 响应状态码表示用户发送了太多请求。

![example](Pasted%20image%2020230529133217.png)

云微服务[\[4\]]( https://www.ibm.com/cloud/learn/microservices )已经变得非常流行，速率限制通常在一个称为 API 网关的组件中实现。API 网关是一个完全托管的服务，支持速率限制、SSL 终止、身份验证、IP 白名单、提供静态内容等功能。目前，我们只需要知道 API 网关是支持速率限制的中间件即可。

在设计速率限制器时，一个重要的问题是：速率限制器应该在服务器端还是在网关中实现？并没有绝对的答案。这取决于您公司当前的技术栈、工程资源、优先级、目标等。以下是一些一般性的指导原则：
- 评估您当前的技术栈，例如编程语言、缓存服务等。确保您当前的编程语言在服务器端实现速率限制时效率高。
- 确定适合您业务需求的速率限制算法。当您在服务器端实现所有内容时，您对算法有完全的控制。但是，如果使用第三方网关，您的选择可能会受到限制。
- 如果您已经使用了微服务架构，并在设计中包含了 API 网关来执行身份验证、IP 白名单等功能，您可以向 API 网关添加速率限制器。
- 自建速率限制服务需要时间。如果您没有足够的工程资源来实现速率限制器，商业 API 网关是一个更好的选择。

### 速率限制算法

速率限制可以使用不同的算法来实现，每种算法都有其独特的优缺点。尽管本章不重点讨论算法，但对它们有一个高层次的理解有助于选择适合我们用例的正确算法或算法组合。以下是一些常见的算法：
- 令牌桶算法
- 漏桶算法
- 固定窗口计数器算法
- 滑动窗口日志算法
- 滑动窗口计数器算法

#### 令牌桶算法

令牌桶算法被广泛用于速率限制。它简单、易于理解，并且被互联网公司普遍使用。亚马逊[\[5\]]( https://docs.aws.amazon.com/apigateway/latest/developerguide/api-gateway-requestthrottling.html )和 Stripe [\[6\]]( https://stripe.com/blog/rate-limiters ) 都使用该算法来限制其 API 请求。

令牌桶算法的工作原理如下：
- 令牌桶是一个预先定义容量的容器。令牌以固定速率周期性地放入桶中。一旦桶满了，就不再添加令牌。如图 4-4 所示，令牌桶的容量为 4。每秒钟填充器向桶中放入 2 个令牌。一旦桶满了，额外的令牌将会溢出。

![work flow](Pasted%20image%2020230529142229.png)

- 每个请求消耗一个令牌。当请求到达时，我们检查桶中是否有足够的令牌。图 4-5 解释了它的工作原理。
  - 如果有足够的令牌，我们会为每个请求取出一个令牌，并且请求会继续进行。
  - 如果没有足够的令牌，请求将被丢弃。

![work flow](Pasted%20image%2020230529142321.png)

图 4-6 说明了令牌消耗、填充和速率限制逻辑的工作方式。在这个示例中，令牌桶大小为 4，每分钟填充 4 个令牌。

![work flow](Pasted%20image%2020230529142541.png)

令牌桶算法有两个参数：
- 桶大小：桶中允许的最大令牌数量
- 填充速率：每秒放入桶中的令牌数量

我们需要多少个令牌桶？这是因情况而异，取决于速率限制规则。以下是一些例子：
- 通常需要为不同的 API 端点设置不同的令牌桶。例如，如果允许用户每秒发布 1 篇帖子，每天添加 150 个好友，并且每秒点赞 5 次帖子，则每个用户需要 3 个桶。
- 如果需要根据 IP 地址限制请求，则每个 IP 地址需要一个桶。
- 如果系统允许每秒最多 10,000 个请求，则使用一个全局桶供所有请求共享是有意义的。

优点：
- 算法易于实现。
- 内存占用效率高。
- 令牌桶允许在短时间内突发流量。只要还有令牌，请求就可以继续通过。

缺点：
- 算法中的两个参数是桶大小和令牌填充速率。然而，调整它们可能会有一定挑战性。

#### 漏桶算法

漏桶算法与令牌桶算法类似，不同之处在于请求以固定速率进行处理。它通常使用先进先出（FIFO）队列来实现。算法的工作方式如下：
• 当请求到达时，系统会检查队列是否已满。如果队列未满，则将请求添加到队列中。
• 否则，请求将被丢弃。
• 请求会按照固定的时间间隔从队列中被取出并进行处理。

图 4-7 解释了该算法的工作原理。

![leaking bucket workflow](Pasted%20image%2020230529143747.png)

漏桶算法具有以下两个参数：
- 桶大小：它等于队列的大小。队列中保存了要以固定速率进行处理的请求。
- 流出速率：它定义了以固定速率可以处理多少个请求，通常以秒为单位。

Shopify 是一家电子商务公司，他们使用漏桶算法进行速率限制。[\[6\]]( https://stripe.com/blog/rate-limiters )

优点：
- 在有限的队列大小下，内存占用效率高。
- 请求以固定速率进行处理，适用于需要稳定流出速率的场景。

缺点：
- 突发流量会使队列填满旧的请求，如果这些请求未能及时处理，最近的请求将受到速率限制。
- 算法中有两个参数，可能不容易正确调整它们。

#### 固定窗口计数器算法 (Fixed window counter)

固定窗口计数器算法的工作原理如下：
- 算法将时间线划分为固定大小的时间窗口，并为每个窗口分配一个计数器。
- 每个请求将计数器增加一。
- 一旦计数器达到预定义的阈值，新的请求将被丢弃，直到新的时间窗口开始。

让我们使用一个具体的例子来看看它是如何工作的。在图 4-8 中，时间单位为 1 秒，系统允许每秒最多 3 个请求。在每个一秒的时间窗口中，如果收到的请求超过 3 个，额外的请求将会被丢弃，如图 4-8 所示。

![Fixed window counter workflow](Pasted%20image%2020230529144359.png)

该算法的一个主要问题是，在时间窗口的边缘出现突发流量可能导致超过允许配额的请求通过。考虑以下情况：

![major problem](Pasted%20image%2020230529144457.png)

在图 4-9 中，系统允许每分钟最多 5 个请求，并在人性化的整分钟时刻重置可用配额。如图所示，在2:00:00和2:01:00之间有五个请求，2:01:00和2:02:00之间又有五个请求。对于2:00:30到2:01:30之间的一分钟窗口，有 10 个请求通过。这是允许请求的两倍。

优点：
- 内存占用效率高。
- 易于理解。
- 在单位时间窗口结束时重置可用配额适用于某些使用情况。

缺点：
- 在时间窗口的边缘出现的流量峰值可能导致超过允许配额的请求通过。

#### 滑动窗口日志算法 (Sliding window log)

在前面讨论的固定窗口计数器算法中存在一个主要问题：在窗口的边缘允许更多的请求通过。滑动窗口日志算法修复了这个问题。它的工作原理如下：
- 算法跟踪请求的时间戳。时间戳数据通常保存在缓存中，例如 Redis 的有序集合[\[8\]]( https://engineering.classdojo.com/blog/2015/02/06/rolling-rate-limiter/ )。
- 当一个新的请求到达时，删除所有过时的时间戳。过时的时间戳被定义为早于当前时间窗口的开始时间。
- 将新请求的时间戳添加到日志中。
- 如果日志的大小与允许的计数相同或更小，则接受请求。否则，请求被拒绝。

我们通过图 4-10 中的例子来解释该算法。

![Sliding window log workflow](Pasted%20image%2020230529145201.png)

在这个例子中，速率限制器允许每分钟 2 个请求。通常，日志中存储的是 Linux 时间戳。但是，为了更好的可读性，我们的例子中使用了人类可读的时间表示。
- 当一个新请求在1:00:01到达时，日志为空。因此，该请求被允许通过。
- 在1:00:30到达一个新请求，时间戳1:00:30被插入到日志中。插入后，日志的大小为 2，不大于允许的计数。因此，该请求被允许通过。
- 在1:00:50到达一个新请求，并插入时间戳到日志中。插入后，日志的大小为 3，大于允许的大小 2。因此，即使时间戳保留在日志中，该请求被拒绝。
- 在1:01:40到达一个新请求。在\[1:00:40,1:01:40\)范围内的请求在最新的时间段内，但是在1:00:40之前发送的请求已经过时。两个过时的时间戳，1:00:01和1:00:30，从日志中删除。删除操作后，日志的大小变为 2；因此，该请求被接受。

优点：
- 该算法实现的速率限制非常准确。在任何滚动窗口中，请求不会超过速率限制。

缺点：
- 该算法消耗大量内存，因为即使请求被拒绝，其时间戳仍可能存储在内存中。

#### 滑动窗口计数器算法 (Sliding window counter)

滑动窗口计数器算法是一种混合方法，结合了固定窗口计数器和滑动窗口日志。该算法可以通过两种不同的方法实现。本节将解释其中一种实现，并在本节末尾提供另一种实现的参考。图4-11说明了该算法的工作原理。 

假设速率限制器允许每分钟最多7个请求，在上一分钟有5个请求，在当前分钟有3个请求。对于一个到达当前分钟30%位置的新请求，滚动窗口中的请求数量可以使用以下公式计算： 
- 当前窗口中的请求数 + 上一个窗口中的请求数 * 滚动窗口和上一个窗口的重叠百分比
- 使用这个公式，我们得到 3 + 5 * 0.7% = 6.5 个请求。根据使用情况，这个数字可以向上或向下取整。在我们的例子中，它向下取整为6。

由于速率限制器每分钟最多允许7个请求，当前请求可以通过。然而，在接收到另一个请求后，将会达到限制。
由于空间有限，我们将不在这里讨论另一种实现。有兴趣的读者应参考参考资料[\[9\]]( https://medium.com/@saisandeepmopuri/system-design-rate-limiter-and-data-modelling9304b0d18250 )。该算法并不完美，它有优点和缺点。
优点：
- 平滑处理流量峰值，因为速率基于前一个窗口的平均速率。 
- 占用内存较少。

缺点：
- 它仅适用于不太严格的回溯窗口。它是对实际速率的近似，因为它假设前一个窗口中的请求是均匀分布的。然而，这个问题可能没有看起来那么严重。根据 Cloudflare 进行的实验[\[10\]]( https://blog.cloudflare.com/counting-things-a-lot-of-different-things/ )，在4亿个请求中，只有0.003%的请求被错误地允许或限制了速率。

###   高层架构 

速率限制算法的基本思想很简单。在高层次上，我们需要一个计数器来跟踪从同一用户、IP 地址等发送的请求数量。如果计数器大于限制值，请求将被拒绝。

我们应该将计数器存储在哪里？使用数据库不是一个好主意，因为磁盘访问速度较慢。选择内存缓存是因为它速度快，并支持基于时间的过期策略。例如，Redis [\[11\]]( https://redis.io/ ) 是实现速率限制的一种常见选择。它是一个内存存储，提供了两个命令：INCR 和 EXPIRE。 
- INCR：它将存储的计数器增加1。
- EXPIRE：它为计数器设置超时时间。如果超时时间到期，计数器会自动被删除。

图4-12显示了速率限制的高层架构，其工作方式如下： 

![](Pasted%20image%2020230529150553.png)

- 客户端发送请求到速率限制中间件。
- 速率限制中间件从 Redis 中的相应桶中获取计数器，并检查是否达到了限制。
  - 如果达到了限制，请求将被拒绝。
  - 如果没有达到限制，请求将被发送到 API 服务器。同时，系统会增加计数器的值并将其保存回 Redis 中。

## Step 3 - 深入设计

高级设计中的图 4-12 无法回答以下问题：
- 如何创建速率限制规则？规则存储在哪里？
- 如何处理被速率限制的请求？

在本节中，我们将首先回答有关速率限制规则的问题，然后讨论处理被速率限制的请求的策略。最后，我们将讨论分布式环境中的速率限制、详细设计、性能优化和监控。

速率限制规则
Lyft 开源了他们的速率限制组件[\[12\]]( https://github.com/lyft/ratelimit )。我们将查看该组件的内部并看一些速率限制规则的示例：
```yaml
Domain: messaging
Descriptors:
  - Key: message_type
    Value: marketing
    Rate_limit:
      Unit: day
      Requests_per_unit: 5
```
在上面的示例中，系统配置为每天最多允许发送 5 条营销消息。这里是另一个示例：

```yaml
Domain: auth
Descriptors:
  - Key: auth_type
    Value: login
    Rate_limit:
      Unit: minute
      Requests_per_unit: 5
```

这个规则表示在 1 分钟内客户端不允许登录超过 5 次。规则通常以配置文件的形式编写并保存在磁盘上。

### 超出速率限制

如果一个请求被速率限制，API 会向客户端返回 HTTP 响应代码 429（太多请求）。根据使用情况，我们可以将被速率限制的请求排队以待稍后处理。例如，如果由于系统过载而导致某些订单被限制速率，我们可以将这些订单保留以待稍后处理。

#### 速率限制器头部信息

客户端如何知道自己是否被限制速率？以及客户端如何知道在被限制速率之前还允许多少请求？答案在于 HTTP 响应头部信息。速率限制器向客户端返回以下 HTTP 头部信息：
X-Ratelimit-Remaining：窗口内剩余允许的请求数量。
X-Ratelimit-Limit：表示客户端每个时间窗口可以发起多少调用。
X-Ratelimit-Retry-After：在不受限制的情况下等待多少秒后可以再次发起请求。

当用户发送了过多的请求时，会返回 429 too many requests的错误和 X-Ratelimit-Retry-After 头部信息给客户端。

### 详细设计

图 4-13 展示了系统的详细设计。

![](Pasted%20image%2020230529151555.png)

- 规则存储在磁盘上。工作节点频繁从磁盘获取规则并将其存储在缓存中。
- 当客户端向服务器发送请求时，请求首先发送到速率限制器中间件。
- 速率限制器中间件从缓存中加载规则。它从 Redis 缓存中获取计数器和上次请求的时间戳。根据响应，速率限制器做出以下决策：
  - 如果请求未被速率限制，则将其转发给 API 服务器。
  - 如果请求被速率限制，则速率限制器向客户端返回 429 太多请求错误。同时，请求要么被丢弃，要么被转发到队列中。

### 分布式环境中的速率限制器

构建一个在单个服务器环境中运行的速率限制器并不困难。然而，将系统扩展到支持多个服务器和并发线程就是另外一回事了。主要存在两个挑战：
- 竞态条件
- 同步问题

#### 竞态条件

如前所述，速率限制器在高层级上的工作原理如下： 
- 从 Redis 中读取计数器的值。 
- 检查是否（计数器+1）超过了阈值。
- 如果没有超过，则在 Redis 中将计数器值增加1。

在高度并发的环境中，竞态条件可能会发生，如图4-14所示。

![](Pasted%20image%2020230529154859.png)

假设Redis中的计数器值为3。如果两个请求同时读取计数器值，在它们中任何一个将值写回之前，每个请求都会将计数器增加1并将其写回，而不会检查另一个线程。这两个请求（线程）都认为它们有正确的计数器值4。然而，正确的计数器值应该是5。

锁是解决竞态条件的最直观的解决方案。然而，锁会显著降低系统的速度。常用的两种解决该问题的策略是使用 Lua 脚本[\[13\]]( https://gist.github.com/ptarjan/e38f45f2dfe601419ca3af937fff574d#request-rate-limiter )和 Redis 中的有序集合数据结构[\[8\]]( https://engineering.classdojo.com/blog/2015/02/06/rolling-rate-limiter/ )。对于对这些策略感兴趣的读者，可以参考相应的参考资料\[8\]\[13\]。

##### 同步问题

在分布式环境中，同步是另一个需要考虑的重要因素。为了支持数百万用户，单个速率限制器服务器可能无法处理流量。当使用多个速率限制器服务器时，需要进行同步。例如，在图4-15的左侧，客户端1向速率限制器1发送请求，客户端2向速率限制器2发送请求。由于 Web 层是无状态的，客户端可以向不同的速率限制器发送请求，如图4-15的右侧所示。如果没有发生同步，速率限制器1将不包含任何关于客户端2的数据。因此，速率限制器无法正常工作。

![](Pasted%20image%2020230529155424.png)

一种可能的解决方案是使用粘性会话，允许客户端将流量发送到相同的速率限制器。这种解决方案并不可取，因为它既不可扩展也不灵活。一个更好的方法是使用像Redis这样的集中式数据存储。设计如图4-16所示。

![](Pasted%20image%2020230529155507.png)

#### 性能优化

性能优化是系统设计面试中的常见主题。我们将涵盖两个方面的改进。 

首先，对于速率限制器来说，多数据中心的设置至关重要，因为对于远离数据中心的用户，延迟很高。大多数云服务提供商在全球各地建立了许多边缘服务器位置。例如，截至2020年5月20日，Cloudflare 拥有194个地理分布的边缘服务器[\[14\]]( https://www.cloudflare.com/learning/serverless/glossary/whatis-edge-computing/ )。流量会自动路由到最近的边缘服务器，以减少延迟。

其次，使用最终一致性模型同步数据。如果对最终一致性模型不清楚，请参考“第6章：设计一个键值存储”中的“一致性”部分。

监控在部署速率限制器之后，收集分析数据以检查速率限制器的有效性非常重要。主要目标是确保： 
- 速率限制算法有效。
- 速率限制规则有效。

例如，如果速率限制规则过于严格，将会丢弃许多有效的请求。在这种情况下，我们希望稍微放宽规则。在另一个例子中，我们注意到在有突发销售等突然增加流量的情况下，我们的速率限制器变得无效。在这种情况下，我们可以更换算法以支持突发流量。Token bucket 算法是一个很好的选择。

##   第4步 - 总结 

在本章中，我们讨论了不同的速率限制算法及其优缺点。讨论的算法包括： 
- 令牌桶算法 
- 漏桶算法 
- 固定窗口算法 
- 滑动窗口日志算法 
- 滑动窗口计数器算法

接下来，我们讨论了系统架构、分布式环境中的速率限制器、性能优化和监控。类似于任何系统设计面试问题，如果时间允许，你可以提及其他一些话题：
- 强限制与软限制。
  -   强限制：请求数量不能超过阈值。
  -   软限制：请求可以在短时间内超过阈值。 
- 在不同层级进行速率限制。在本章中，我们只讨论了在应用层（HTTP：第7层）进行速率限制的情况。还可以在其他层级应用速率限制。例如，可以使用 Iptables [15]（IP：第3层）按 IP 地址进行速率限制。
  注意：开放系统互连（OSI）模型共有7层[16]：第1层：物理层第2层：数据链路层第3层：网络层第4层：传输层第5层：会话层第6层：表示层第7层：应用层 
- 避免被限制。设计客户端时要遵循最佳实践：
  -   使用客户端缓存以避免频繁调用 API。
  -   了解限制，不要在短时间内发送过多的请求。
  -   添加捕获异常或错误的代码，以便客户端可以从异常中优雅地恢复。
  -   在重试逻辑中添加足够的退避时间。
  
祝贺你走到了这一步！现在给自己一个鼓励。干得好！